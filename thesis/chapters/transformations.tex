% !TEX root = ../thesis.tex
%
\chapter{Compiler Transformations}
\label{sec:transformations}

After discussing possible optimizations to the labyrinth algorithm in chapter~\ref{sec:preliminary}, we will now attempt to generalize the changes we made into transformations to be applied at compile time.
The resulting transformations will be formally described and discussed in this chapter, using an Expression IR that is based on the lambda calculus.
\todo{Maybe rewrite Introductory Passage}

\section{Expression IR Definition}%
\label{sec:transformations:expression-ir}

\begin{figure}[p]
    \begin{tabular}{l c l r}
        \multicolumn{4}{l}{\emph{Terms:}}\\
        $t$ & $::=$ & $x$ & variable\\
        & $|$ & $\lambda x.t$ & abstraction\\
        & $|$ & $t\ t$ & application\\
        & $|$ & \texttt{let} $x = t$ \texttt{in} $t$ & lexical scope (variable binding)\\
        & $|$ & \texttt{if}$(t\ t\ t)$ & conditionals\\
        & $|$ & \texttt{let} $f = \lambda x.t$ \texttt{in} & fixed-point combinator\\
        & $|$ & $\texttt{ff}_f (x_1 \dots x_n)$ & apply the free foreign function $f$ to $x_1 \dots x_n$\\
        &&& with $n \geq 0$.\\
        & $|$ & $\texttt{sf}_f (s x_1 \dots x_n)$ & apply the state-modifying foreign function $f$\\
        &&& to state $s$ and $x_1 \dots x_n$ with $n \geq 0$.\\\ \\
    
        \multicolumn{4}{l}{\emph{Values:}}\\
        $v$ & $::=$ & $o \in V_\text{h}$ & value in host language\\
        & $|$ & $\lambda x.t$ & abstraction\\
        & $|$ & $[ v_1 \dots v_n ]$ & list of $n$ values\\\ \\ \
    \end{tabular}
    
    \begin{tabular}{l c l}
        \multicolumn{3}{l}{\emph{Predefined Functions:}}\\
        \texttt{map}$(\lambda x.t\ [ v_1 \dots v_n ])$ & $\equiv$ & $[ (\lambda x.t)\ v_1\ \dots \ (\lambda x.t)\ v_n ]$\\
        \texttt{nth}$(n \ [ v_1 \dots v_n \dots v_p])$ & $\equiv$ & $v_n$\\
        \texttt{split}$(n \ [ v_1 \dots v_n \dots v_p])$ & $\equiv$ & $[ [v_1 \dots v_{\frac{n}{p}}]\ \dots \ [v_{\frac{(p-1) n}{p} + 1} \dots v_n] ]$\\
        \texttt{join}$([ [v_1 \dots v_{\frac{n}{p}}]\ \dots \ [v_{\frac{(p-1) n}{p} + 1} \dots v_n] ])$ & $\equiv$ & $[ v_1 \dots v_n \dots v_p]$
    \end{tabular}
    \caption{Language definition of the Expression IR.}%
    \label{fig:transformations:definition}
\end{figure}

\begin{figure}[p]
    $\texttt{let } f = \lambda x y.$\\
    \hspace*{.3cm}$\texttt{let } x_\text{paths} = \texttt{map} (\lambda z.\texttt{ff}_\text{find\_path} (x\ z)$\\
    \hspace*{3.2cm}$y) \texttt{ in}$\\
    \hspace*{.6cm}$\texttt{let } x_\text{resulting\_maze}\ x_\text{not\_mapped} = \texttt{sf}_\text{update}(x\ x_\text{paths}) \texttt{ in}$\\
    \hspace*{.9cm}$\texttt{let } x_\text{number\_unmapped} = \texttt{ff}_\text{count} (x_\text{not\_mapped}) \texttt{ in}$\\
    \hspace*{1.2cm}$\texttt{if } (x_\text{number\_unmapped} = 0$\\
    \hspace*{2cm}$x_\text{resulting\_maze}$\\
    \hspace*{2cm}$f\ x_\text{resulting\_maze}\ x_\text{not\_mapped}) \texttt{ in}$\\
    \caption{Expression for our labyrinth algorithm as outlined in chapter~\ref{sec:preliminary:labyrinth}.}%
    \label{fig:transformations:ir-first-stage}
\end{figure}

During compilation, the Ohua compiler framework parses algorithms provided as inputs into an Expression IR on which it then runs a number of optimizations, as we have shown in Figure~\ref{fig:background:ohua} in chapter~\ref{sec:background:ohua}.
We are going to describe our transformations in this intermediate representation, which we will therefore present now briefly.
The Expression IR we use is based on the call-by-need lambda calculus~\cite{ariola1997lambda, ariola1995lambda} which prevents duplicated computations.\todo{Link io-paper here as we've used it there already?}
Figure~\ref{fig:transformations:definition} defines our expression language, which is building atop the language used in previous research on Ohua optimizations~\cite{ertel2018compiling} by Ertel et al.
The language defines the basic terms of the call-by-need lambda calculus for variables, abstractions, application and lexical scoping.
We additionally define conditionals and fixed-point combinators to realize recursive expressions\todo{Elaborate on fixed-point combinator?} as well as free and state-modifying foreign functions.
Using the combinator $\text{ff}_f$ one can express the application of a function $f$ which is not defined as part of the calculus to an arbitraty number of arguments.
This allows us to integrate code written in other languages like Rust into the algorithm, which is a key premise for Ohua's concept as Embedded DSL.
Furthermore, we expand the definitions used in previous work by adding the combinator $\text{sf}_f$, which applies a method $f$ to a state value $s$ and an arbitrary number of additional values.
We made this addition in order to model the state manipulations usually found in shared state applications.
Methods that are executed on a state value may alter it but are usually also allowed to return another value (e.g., when reading from a piece of state).
This behavior is reflected in the \texttt{sf} combinator producing a list with two values as result, where the first value is the the altered state value and the second value is the ordinary value produced by the function $f$.

In order to complete the includion of legacy code into the Expression IR, values may not only be abstractions or lists of values but also values in $V_\text{h}$, the value domain of the host language.
Aside from recursion, we also define the well-known higher-order function \texttt{map} which applies a term to a list of values and the function \texttt{nth} to retrieve a particular element from a list of values.
The function \texttt{split} separates an input list into equally sized chunks, while the function \texttt{join} reverses this operation, flattening a list of lists into a single large list.\todo{$n \leq p$ angeben?}
Both functions cancel each other out:
\begin{align*}
    \texttt{join}(\texttt{split}(n \ [v_1 \dots v_n])) \equiv [v_1 \dots v_n]
\end{align*}

As a shorthand for writing more concise terms, we introduce a simple destructuring syntax which is defined as follows:\todo{make actual definitions?}
\begin{center}
    \begin{tabular}{l c l}
        && \texttt{let} $x_{\text{result}} = \texttt{ff}_f() \texttt{ in}$\\
        \texttt{let} $y\ z = \text{ff}_f() \texttt{ in}$ & $\equiv$ & \ \ \texttt{let} $y = \texttt{nth}(1\ x_{\text{res}}) \texttt{ in}$\\
        && \ \ \ \ \texttt{let} $z = \texttt{nth}(2\ x_{\text{res}}) \texttt{ in}$\\
    \end{tabular}
\end{center}

Using our defined calculus, we can now define an expression that describes our labyrinth benchmark from chapter~\ref{sec:preliminary:labyrinth}.
Figure~\ref{fig:transformations:ir-first-stage} shows the \texttt{fill} algorithm as lambda expression, to which we will apply our transformations.

\section{Map Parallelization}%
\label{sec:transformations:tf1}

The base idea of our first optimization developed in chapter~\ref{sec:preliminary:tf1} was to execute the path finding in parallel to make use of the multi-threading functionalities of modern commodity CPUs.
This was possible because the path-finding loop in itself does not contain any state update and the loop iterations themselves are independent of one another.
Since we want to have as few application logic as possible in the code generation and the runtime, it makes sense to move this optimization into the Expression IR optimization stage.
To achieve a low-cost parallelization that does not require any knowledge about parallel loops in the runtime, we simply split the loop in question into a number of smaller loops.
As these small loops do not exhibit any data dependencies between one another, the execution runtime can run them in parallel without having to understand, what these operators are.

Although we did this in our specific example for the problem of pathfinding, this can indeed be generalized.
Each \texttt{map} combinator which does not modify state internally, i.e., does not entail \texttt{sf} combinators, may be parallelized in this way.
Using the predefined functions \texttt{split} and \texttt{join} we define the transformation to adapt a map operation for $p$ threads:

\begin{figure}[h]
    \begin{tabular}{l c l}
        \multirow{5}{*}{$\texttt{let } r = \texttt{map} (t\ [v_1 \dots v_n]) \texttt{ in}$} & \multirow{5}{*}{$\underset{\text{p threads}}{\longrightarrow}$} & $\texttt{let } m_1 \dots m_p = \texttt{split} (p\ [v_1 \dots v_n]) \texttt{ in}$\\
                                                                                            &&\hspace*{.3cm} $\texttt{let } r_1 = \texttt{map} (t\ m_1) \texttt{ in}$\\
                                                                                            &&\hspace*{.6cm} $\dots$\\
                                                                                            &&\hspace*{.9cm} $\texttt{let } r_p = \texttt{map} (t\ m_p) \texttt{ in}$\\
                                                                                            &&\hspace*{1.2cm} $\texttt{let } r = \texttt{join} ([r_1 \dots r_p]) \texttt{ in}$\\
    \end{tabular}
    \caption{Transformation 1: Map Parallelization for $p$ threads.}%
    \label{fig:transformations:tf1}
\end{figure}

This transformation turns a single stateless map operation into $p$ independent map operations which can then be individually scheduled and executed.
To prove the semantic correctness of this transformation, we can show that the left and the right expression are indeed equivalent by resolving the right expression bottom-up:
\begin{align*}
    \texttt{join} ([r_1 \dots r_p]) &\equiv \texttt{join} (\texttt{map} (t\ m_1) \dots \texttt{map} (t\ m_p))\\
                                    &\equiv \texttt{join} ([[t\ v_1 \dots t\ v_{\frac{n}{p}}] \dots [t\ v_{\frac{(p-1) n}{p} + 1} \dots t\ v_n]])& \text{\small by map definition}\\
                                    &\equiv \texttt{join} (\texttt{split} (p\ [t\ v_1 \dots t\ v_n]))\\
                                    &\equiv [t\ v_1 \dots t\ v_n]\\
                                    &\equiv \texttt{map} (t\ [v_1 \dots v_n])
\end{align*}

Using this rather simple transformation we are now abl to split state-free loop into smaller chunks of work that can be executed in parallel due to the absence of data dependencies.


% TODO: Zeigen, dass wir von einem simplen Start-Algo ausgehen (simpler als der im vorherigen Chapter) und der dann umgewandelt werden soll intern in das, was wir davor gezeigt haben.

% - take the optimizations we've done and generalize them
% - give formal definitions of the optimizations if possible
%   - discuss the effect it has
%   - are the optimizations semantics preserving?
%   - is it *valid* to do these transformations?
% - discuss whether the optimizations have to be applied in certain order
